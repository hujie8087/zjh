<!doctype html>
<html>
  <head>
    <title>AudioWorkletNode 示例</title>
  </head>
  <body>
    <script>
      // 获取用户媒体设备的音频流
      navigator.mediaDevices
        .getUserMedia({ audio: true })
        .then(function (stream) {
          // 创建音频上下文
          const audioContext = new AudioContext()

          // 创建MediaStreamAudioSourceNode，用于将音频流连接到音频图中
          const sourceNode = audioContext.createMediaStreamSource(stream)

          // 创建ScriptProcessorNode，指定缓冲区大小和输入输出声道数
          const scriptNode = audioContext.createScriptProcessor(4096, 1, 1)

          // 连接节点
          sourceNode.connect(scriptNode)
          scriptNode.connect(audioContext.destination)

          // 监听音频数据的回调函数
          scriptNode.onaudioprocess = function (audioProcessingEvent) {
            const audioChunks = []
            // 获取输入缓冲区
            const inputBuffer = audioProcessingEvent.inputBuffer
            // 获取输出缓冲区
            const outputBuffer = audioProcessingEvent.outputBuffer

            // 处理音频数据
            for (let channel = 0; channel < inputBuffer.numberOfChannels; channel++) {
              const inputData = inputBuffer.getChannelData(channel)
              audioChunks.push(new Float32Array(inputData))
            }

            console.log(`output->`, audioChunks)
          }
        })
        .catch(function (error) {
          console.log('获取音频流失败：', error)
        })
    </script>
  </body>
</html>
